# Transformada de Hough en CUDA

Proyecto de ComputaciÃ³n Paralela y Distribuida - Universidad del Valle de Guatemala

## DescripciÃ³n

ImplementaciÃ³n paralela de la Transformada Lineal de Hough usando CUDA para la detecciÃ³n de lÃ­neas rectas en imÃ¡genes binarias (blanco y negro). El proyecto explora el uso de diferentes tipos de memoria GPU (Global, Constante y Compartida) para optimizar el rendimiento.

## Equipo

- **Integrante 1**: Silvia Illescas - 22376
- **Integrante 2**: Isabella Miralles - 22293
- **Integrante 3**: Michelle MejÃ­a - 22596

**Docente**: Marlon Fuentes
**Semestre**: 2, 2025
**Fecha de Entrega**: Semana del 12-14 de noviembre, 2025

## Objetivos

- Implementar la Transformada de Hough en CUDA
- Explorar el uso de memoria Constante para valores trigonomÃ©tricos precalculados
- Utilizar memoria Compartida para reducir accesos a memoria Global
- Comparar el rendimiento de diferentes estrategias de memoria
- Visualizar las lÃ­neas detectadas en imÃ¡genes

## Estructura del Proyecto

Proyecto3-CUDA-Paralela/

â”œâ”€â”€ README.md

â”œâ”€â”€ Makefile

â”œâ”€â”€ .gitignore

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ hough.cu              # ImplementaciÃ³n principal

â”‚   â”œâ”€â”€ hough.h               # Headers y definiciones

â”‚   â””â”€â”€ image_utils.cpp       # Utilidades para manejo de imÃ¡genes

â”œâ”€â”€ images/

â”‚   â”œâ”€â”€ input/                # ImÃ¡genes de entrada

â”‚   â””â”€â”€ output/               # ImÃ¡genes con lÃ­neas detectadas

â”œâ”€â”€ results/

â”‚   â”œâ”€â”€ measurements.csv      # Mediciones de tiempo

â”‚   â””â”€â”€ analysis.xlsx         # AnÃ¡lisis de resultados

â”œâ”€â”€ docs/

â”‚   â”œâ”€â”€ informe.pdf           # Informe final

â”‚   â”œâ”€â”€ presentacion.pptx     # PresentaciÃ³n ejecutiva

â”‚   â””â”€â”€ bitacora.md           # BitÃ¡cora de desarrollo

â””â”€â”€ scripts/

â”‚   â””â”€â”€ run_tests.sh          # Script para ejecutar pruebas


## CompilaciÃ³n y EjecuciÃ³n

### Requisitos

- CUDA Toolkit (versiÃ³n 11.0 o superior)
- GCC/G++ compatible con CUDA
- GPU NVIDIA con compute capability 3.0+
- OpenCV (opcional, para visualizaciÃ³n)

### Compilar

\`\`\`bash
make clean
make
\`\`\`

### Ejecutar

\`\`\`bash
# VersiÃ³n bÃ¡sica
./hough images/input/test.pgm

# Con parÃ¡metros personalizados
./hough images/input/test.pgm --threshold 50 --output images/output/result.png
\`\`\`

## Versiones Implementadas

### VersiÃ³n 1: Memoria Global
- [x] CÃ¡lculo correcto de `gloID`
- [x] Kernel bÃ¡sico funcional
- [x] MediciÃ³n de tiempos con CUDA Events
- [x] LiberaciÃ³n de memoria

**Tiempo promedio**: ___ ms

### VersiÃ³n 2: Memoria Global + Constante
- [x] DeclaraciÃ³n de `d_Cos` y `d_Sin` en memoria constante
- [x] Uso de `cudaMemcpyToSymbol`
- [x] EliminaciÃ³n de parÃ¡metros del kernel
- [x] MediciÃ³n de tiempos

**Tiempo promedio**: ___ ms  
**Mejora**: ___% respecto a versiÃ³n 1

### VersiÃ³n 3: Global + Constante + Compartida
- [x] Acumulador local en memoria compartida
- [x] Uso de barreras (`__syncthreads()`)
- [x] Operaciones atÃ³micas para sincronizaciÃ³n
- [x] ReducciÃ³n de accesos a memoria global

**Tiempo promedio**: ___ ms  
**Mejora**: ___% respecto a versiÃ³n 2

## Algoritmo: Transformada de Hough

### Concepto

La Transformada de Hough convierte puntos en el espacio de imagen (x, y) al espacio de parÃ¡metros (Î¸, r), donde:

- **Î¸**: Ãngulo perpendicular a la lÃ­nea (0Â° a 180Â°)
- **r**: Distancia del origen a la lÃ­nea

### FÃ³rmula

\`\`\`
r(Î¸) = xÂ·cos(Î¸) + yÂ·sin(Î¸)
\`\`\`

### Proceso

1. Para cada pixel "blanco" en la imagen
2. Iterar sobre todos los Ã¡ngulos Î¸ posibles
3. Calcular r(Î¸) usando la fÃ³rmula
4. Incrementar el acumulador en la posiciÃ³n (Î¸, r)
5. Las celdas con mÃ¡s votos representan lÃ­neas en la imagen

## Resultados

### Tabla Comparativa de Tiempos

| VersiÃ³n | Tiempo Promedio (ms) | Desv. EstÃ¡ndar | Mejora (%) |
|---------|---------------------|----------------|------------|
| Global  | -                   | -              | -          |
| + Constante | -               | -              | -          |
| + Compartida | -              | -              | -          |

### ImÃ¡genes de Resultados

Pendiente


## Pruebas y Mediciones

### MetodologÃ­a

- **NÃºmero de mediciones**: 10 por versiÃ³n
- **Imagen de prueba**: [Especificar dimensiones y caracterÃ­sticas]
- **ConfiguraciÃ³n del grid**: [Especificar bloques y threads]
- **Hardware**: [Especificar GPU utilizada]

### Ejecutar Pruebas

\`\`\`bash
./scripts/run_tests.sh
\`\`\`

## Optimizaciones Implementadas

### Memoria Constante
- **Ventaja**: Broadcast eficiente de valores trigonomÃ©tricos a todos los threads
- **Uso**: Almacenar cos(Î¸) y sin(Î¸) precalculados
- **Impacto**: ReducciÃ³n de cÃ¡lculos trigonomÃ©tricos costosos

### Memoria Compartida
- **Ventaja**: Baja latencia, acceso rÃ¡pido entre threads del mismo bloque
- **Uso**: Acumulador local por bloque
- **Impacto**: ReducciÃ³n de accesos a memoria global y contenciÃ³n atÃ³mica

### Operaciones AtÃ³micas
- **Uso**: `atomicAdd()` para actualizar acumuladores sin race conditions
- **UbicaciÃ³n**: Tanto en memoria compartida como global

## Debugging

Para habilitar mensajes de debug:

\`\`\`cpp
#define DEBUG 1
\`\`\`

## Referencias

1. NVIDIA CUDA C Programming Guide
2. "Digital Image Processing" - Gonzalez & Woods
3. [CUDA Performance Metrics](https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/)
4. [Hough Transform - Wikipedia](https://en.wikipedia.org/wiki/Hough_transform)

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad del Valle de Guatemala
